import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import fs from 'fs';
import path from 'path';

// ============================================
// ğŸ“Œ STT API - Speech-to-Text Transcription
// ============================================
// POST /api/transcribe
// - ìŒì„± íŒŒì¼ì„ ë°›ì•„ì„œ OpenAI Whisper APIë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
// - ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ txt íŒŒì¼ë¡œ ì €ì¥
// - ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜
//
// í…ŒìŠ¤íŠ¸ ëª¨ë“œ: .env.localì— TEST_MODE=true ì¶”ê°€ ì‹œ
// OpenAI API í˜¸ì¶œ ì—†ì´ ëª¨ì˜(mock) ì‘ë‹µ ë°˜í™˜

// TEST_MODEê°€ í™œì„±í™”ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const TEST_MODE = process.env.TEST_MODE === 'true';
const openai = TEST_MODE
  ? null
  : new OpenAI({
      apiKey: process.env.OPENAI_KEY,
    });

export async function POST(request: NextRequest) {
  try {
    // 1. FormDataì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;

    if (!audioFile) {
      return NextResponse.json(
        { error: 'ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.' },
        { status: 400 }
      );
    }

    // 2. File ê°ì²´ë¥¼ Bufferë¡œ ë³€í™˜
    const arrayBuffer = await audioFile.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);

    // 3. ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (OpenAI APIëŠ” íŒŒì¼ ê²½ë¡œ í•„ìš”)
    const tempDir = path.join(process.cwd(), 'transcriptions');
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    const tempFilePath = path.join(tempDir, `temp_${Date.now()}.wav`);
    fs.writeFileSync(tempFilePath, buffer);

    let transcriptionText: string;

    // 4. OpenAI Whisper APIë¡œ ìŒì„±â†’í…ìŠ¤íŠ¸ ë³€í™˜ (ë˜ëŠ” í…ŒìŠ¤íŠ¸ ëª¨ë“œ)
    if (TEST_MODE) {
      // í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ëª¨ì˜ ì‘ë‹µ ë°˜í™˜
      console.log('ğŸ§ª TEST_MODE: OpenAI API í˜¸ì¶œ ê±´ë„ˆë›°ê¸°');
      transcriptionText = '[í…ŒìŠ¤íŠ¸ ëª¨ë“œ] ì´ê²ƒì€ ëª¨ì˜ ìŒì„± ë³€í™˜ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì‹¤ì œ OpenAI APIë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ TEST_MODEë¥¼ falseë¡œ ì„¤ì •í•˜ê³  ìœ íš¨í•œ API í‚¤ì™€ í¬ë ˆë”§ì„ í™•ì¸í•˜ì„¸ìš”.';
      
      // ì„ì‹œ íŒŒì¼ ì‚­ì œ
      fs.unlinkSync(tempFilePath);
    } else {
      // ì‹¤ì œ OpenAI API í˜¸ì¶œ
      if (!openai) {
        throw new Error('OpenAI client is not initialized');
      }
      
      const transcription = await openai.audio.transcriptions.create({
        model: 'whisper-1',
        file: fs.createReadStream(tempFilePath),
      });

      // ì„ì‹œ íŒŒì¼ ì‚­ì œ
      fs.unlinkSync(tempFilePath);
      
      transcriptionText = transcription.text;
    }

    // 6. ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ txt íŒŒì¼ë¡œ ì €ì¥
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const txtFileName = `transcription_${timestamp}.txt`;
    const txtFilePath = path.join(tempDir, txtFileName);

    fs.writeFileSync(txtFilePath, transcriptionText, 'utf-8');

    // 7. ê²°ê³¼ ë°˜í™˜
    return NextResponse.json({
      success: true,
      text: transcriptionText,
      filePath: txtFilePath,
      fileName: txtFileName,
      timestamp: new Date().toISOString(),
      testMode: TEST_MODE, // í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì—¬ë¶€ í‘œì‹œ
    });
  } catch (error) {
    console.error('Transcription error:', error);

    return NextResponse.json(
      {
        error: 'ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        details: error instanceof Error ? error.message : 'Unknown error',
      },
      { status: 500 }
    );
  }
}
